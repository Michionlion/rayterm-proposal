\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
% \usepackage[skip=3em]{caption}

\topmargin -4em
\setlength{\textwidth} {420pt}
\setlength{\textheight} {620pt}
\setlength{\oddsidemargin} {20pt}
\setlength{\marginparwidth} {72in}


\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{mathtools}

% Use elastic spacing around the headers
\usepackage{titlesec}
\titlespacing\section{0pt}{6pt plus 4pt minus 2pt}{4pt plus 2pt minus 2pt}

% set it so that subsubsections have numbers and they
% are displayed in the TOC (maybe hard to read, might want to disable)
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

% define widow protection
\def\widow#1{\vskip #1\vbadness10000\penalty-200\vskip-#1}

\clubpenalty=10000  % Don't allow orphans
\widowpenalty=10000 % Don't allow widows

% this should give you the ability to use some math symbols that
% were available by default in standard latex (i.e. \Box)
\usepackage{latexsym}

% define a little section heading that doesn't go with any number
\def\littlesection#1{
  \widow{2cm}
  \vskip 0.5cm
  \noindent{\bf #1}
  \vskip 0.0001cm
}

\pagestyle{fancyplain}

\newcommand{\tstamp}{\today}

% \renewcommand{\sectionmark}[1]{\markright{#1}}
% \lhead[\Section \thesection]            {\fancyplain{}{\rightmark}}
% \chead[\fancyplain{}{}]                 {\fancyplain{}{}}
% \rhead[\fancyplain{}{\rightmark}]       {\fancyplain{}{\thepage}}
% \cfoot[\fancyplain{\thepage}{}]         {\fancyplain{\thepage}{}}
%
% \newlength{\myVSpace}% the height of the box
% \setlength{\myVSpace}{1ex}% the default,
% \newcommand\xstrut{\raisebox{-.5\myVSpace}% symmetric behaviour,
%   {\rule{0pt}{\myVSpace}}%
% }

% leave things with no spacing extra spacing in the final version of the paper
\renewcommand{\baselinestretch}{1.0} % must go before the begin of doc

% suppress the use of indentation for a paragraph
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.1in}


% custom commands
\newcommand{\name}{{\sc RayTerm}}
\newcommand{\rayorg}{\vec{R_{origin}}}
\newcommand{\raydir}{\vec{R_{direction}}}

% begin actual document

\begin{document}

% handle widows appropriately
\def\widow#1{\vskip #1\vbadness10000\penalty-200\vskip-#1}

% make the title section

\thispagestyle{empty}
\begin{center}
  {\Huge
    \name
    \par
  }
  {\LARGE
    A Ray-Tracing Rendering Engine for XTerm-like Terminals
    \par
  }
  {\normalsize
    Saejin Mahlau-Heinert \\
    Department of Computer Science \\
    Allegheny College \\
    {\tt mahlauheinerts@allegheny.edu} \\
    \url{https://saejinmh.com} \\
    \vspace*{.1in} \today \\ \vspace*{.1in}
    \par
  }
  \vskip 2em
\end{center}

% Default "abstract" environment is too small; customize one instead:
\begin{center}
  \large\bf Abstract
  \vspace{-1em}
\end{center}

\begin{quote}

Over the many years of innovation in the field of computer graphics, advances in rendering have led to massive increases in the fidelity of engaging, satisfying, and realistic computer visualizations.
\name\ is a new and unique entry into the ranks of rendering engines, and makes its own contributions to the field of computer graphics.
While harkening back to the retro aesthetics of the seventies and eighties, \name\ embraces new advances in computing power to bring fully ray-traced visuals to an old screen -- the terminal.
Using Unicode block characters to simulate pixels and a ray-tracer written in C++, a fully three dimensional scene can be rendered, complete with lighting, shadows, and physically-based materials.
\name\ can be used as an engine for terminal-based 3D tools, visualizations, games, and more; it will be fully open-source and ready for integration into other projects.

\end{quote}

\section{Introduction}
\label{sec:introduction}

% Provide an intuitive motivation for and introduction to your proposed senior
% thesis research. Whenever possible, you should use one or more concrete examples
% and technical diagrams.

In the early days of computing, real-time rendering engines that powered games like {\it Doom} or {\it NetHack} had to run on extremely underpowered hardware, and render to low-resolution screens.
The dream of real-time, photorealistic graphics was far, far away.
However, even then the appeal of simple, blocky graphics, easily recognizable shapes, and maze-like environments were fantastic entertainment.
Today the retro-style of low-resolution graphics, pixel art, and 8-bit color is abound in the gaming space.
This proposal is one part of enabling that retro-aesthetic to grow into a new and unique style that, while similar to the old classics, can be more engaging and real than they ever could.
With the current generation of powerful GPU and CPU chips, able to execute billions and trillions of calculations per second, it is finally possible to do real-time, close to photorealistic rendering, given some slight handicaps.


This proposal describes a system that will create what are, in essence, images on a terminal screen.
This rendering engine will perform real-time updating of the displayed image, generating an animation.
The system will use the recursive ray-tracing algorithm, simulating the path of light through the scene -- this is described in more detail in Section ~\ref{sec:introduction:raytracing}.
Rendered images will be displayed in two different modes: using single half-character pixels, or more complex Unicode block characters.
The mechanics of this image composition method are discussed in Section ~\ref{sec:introduction:unicode}.
Once an image is rendered, the \texttt{ncurses} C library \cite{ncursesLibrary} will be used to display it in a terminal.
The final terminal output will be similar to Figure ~\ref{fig:checker_metal}, which was generated by TerminalImageViewer \cite{tivGithub} as a mockup.
More detail on this process are given in Section ~\ref{sec:introduction:ncurses}.


\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{resources/checker_metal}
  \caption{Example of proposed terminal output}
  \label{fig:checker_metal}
\end{figure}

\subsection{Rendering Engines and Ray-Tracing}
\label{sec:introduction:raytracing}

A rendering engine is an algorithm that takes a scene -- a description of some space with objects -- and generates an image or visual representation of that scene.
There are many different algorithms to do this; in this proposal the recursive ray-tracing algorithm, first pioneered by Turner Whitted in his ground-breaking paper {\it An Improved Illumination Model for Shaded Display} \cite{whitted1980improved}, will be discussed and utilized.
Ray-tracing was one of the first algorithms developed in the field of computer graphs, and although there have been some improvements since then, the idea behind the algorithm is fairly straight forward.

Ray-tracing has been used as the renderer of choice for photorealistic images, since with a few modification's from Whitted's original algorithm, it can generate fantastic images.
In the past, however, it has been reserved for non-real-time uses.
For example, Figure ~\ref{fig:povray_render} is a render created by the POV-Ray engine \cite{povray}.
POV-Ray can take between a few minutes to several hours to complete one single image depending on the processing power involved.
However, there have been a few recent innovations that change this, and more details on this, as well as how ray-tracing will be utilized for this proposed system, are discussed in Section \ref{sec:method}.

\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{resources/glasses_povray}
  \caption{POV-Ray render created by Gilles Tran}
  \label{fig:povray_render}
\end{figure}


Ray-tracing revolves around the idea of {\it rays}, a mathematical construct which can be defined by two vectors: an origin point, referred to as $\rayorg$ for some ray $R$, and a direction, referenced as $\raydir$.
These two vectors together represent a ray that starts at the origin and projects along the direction; it is of infinite length. An important addition to the concept of rays is a point along a ray -- this can be defined by using a third variable, which we will call $t$, to represent how far along the ray the point is located.
Therefore, formula ~\ref{equation:point_on_ray} can be used to get the coordinates of a point in three-dimensional space (assuming $\raydir$ is a unit vector). This is called the {\it paramatric~form} of a ray. The mathematics behind ray-tracing are further explored in Section ~\ref{sec:method}.

\begin{equation}
  \label{equation:point_on_ray}
  \vec{point} = \rayorg + t\raydir
\end{equation}

In ray-tracing, rays are used to simulate the path that light takes as it travels around the scene.
When a ray intersects with an object in the scene, various things can happen to simulate how light may travel under different conditions.
It is worth noting that a base assumption is made in ray-tracing when using straight rays as described here: light follows a straight line without changes.
This is only the case in reality when light travels through a vacuum with no gravitational bodies; thus basic ray-tracing is not exactly photorealistic, and does not model phenomena such as atmospheric scattering.
Additional mathematics and systems must be used to bend, attenuate, or scatter a ray to accurately render transparent volumes -- this is called volumetric ray-tracing, and will not be supported by \name, at least in the version proposed here.

The basis for ray-tracing is the rendering equation, articulated by James Kajiya in 1986 \cite{kajiya1986rendering}.
The mathematics behind the equation are covered in Section \ref{sec:method:rendering_equation}; a simplified description is that the rendering equation models the outgoing light at some point given all incoming light, a bidirectional reflectance distribution function (BDRF) and a normal for the surface at the point modeled.
If solved for every point in the scene, the rendering equation could generate a completely photorealistic image -- this would, however, require massive amounts of computation since the integral over all incoming light must be solved through numerical analysis.
Ray-tracing engines that do this are known as {\it path-tracers}, and are the most photorealistic rendering engines invented.

\name\ will not use a path-tracer -- they are still many times too slow for real-time rendering.
Instead, the rendering equation will solved by sampling the incoming light with rays.
This is known as recursive ray-tracing, since we will start with a single ray which will split every time it encounters a surface.
The eventual goal of the recursive ray-traving algorithm is to create a tree of rays for each {\it fragment} to render.
A fragment is either a pixel or some sub-pixel -- many systems will use four or more fragments per pixel to get better anti-aliasing and more accurate results.
Each ray has some color that represents the color of the light in that ray; when a ray hits an object, it is {\it scattered} by the {\it material} of the object, splitting and generating new rays. These rays are biased towards directions that contain lots of incoming light -- such as towards a point light source. The specific implementation of recursive ray-tracing that \name\ will use will only scatter into a set number of rays at each intersection point -- one ray toward each light source, along with reflection and refraction rays towards the relevant directions.

The base of each generated tree is a ray -- called an {\it eye-ray} -- with its origin at the camera or ``eye''.
The eye-ray's color is the color that will be rendered for that fragment.
As the eye-ray projects forward, away from the eye, it is tested for intersection with all objects in the scene.
When an intersection happens and the generated rays scattered, the eventual color values of the scattered rays are combined to produce the color of the original eye-ray. This is done recursively to fully render the scene.


\subsection{Image Composition using Unicode Characters}
\label{sec:introduction:unicode}

Unicode is a character standard that allows anyone to reference many thousands of characters to compose text, no matter the environment around the text. Some critical characters that \name\ will use are known as the {\it block characters} -- they are characters \texttt{U+2580}--\texttt{U+259F}. Contingent on the quality of the output using only block characters, additional sets could be used such as triangles and lines. The core of image composition using Unicode is coloring the characters and the background -- \name\ will use this so that every character of the output contains two colors -- one for the background, and one for the character displayed. This allows each {\it character~pixel} to represent a hard gradient.

There are two image modes that will be available for use in \name. The first is pure {\it pixel mode}, in which the unicode ``half-block'' symbol is used. Since mono-spaced character output (such as in a terminal) is twice as tall as it is wide, the half-block can split a single character into two pixels that are colored differently -- the upper pixel with the background color of the character, and the lower with the character or foreground color of the pixel. This would mean that a typical 85 by 30 character terminal would result in a screen space of 85 by 60 pixels. This mode also dramatically reduces the number of ray-tracing computations needed, since only one ray per pixel is required.

The second image mode is considerably more complicated and slower, as it uses significantly more rays per character in order to determine what Unicode block character most fits the desired output. On the other hand, it allows much higher perceived resolution, since the characters used have smaller footprints -- up to an eigth of a character in width or length. The differences between these two modes are highlighted in Figure \ref{fig:unicode_mode_comparison1} and \ref{fig:unicode_mode_comparison2}. It can be seen that the first image mode, {\it pixel mode}, has a rather fuzzy definition of the sphere, whereas in the second image mode, {\it block character mode}, the sphere itself, as well as the reflections seen on it, are much more defined. The performance impact of both modes is another factor that must be assessed when choosing how to implement \name.

\begin{figure}[htb]
  \begin{subfigure}[htb]{0.5\textwidth}
    \includegraphics[width=\textwidth]{resources/many_spheres_square}
    \caption{Pixel Mode Image Output}
    \label{fig:unicode_mode_comparison1}
  \end{subfigure}
  \begin{subfigure}[htb]{0.5\textwidth}
    \includegraphics[width=\textwidth]{resources/many_spheres}
    \caption{Character Mode Image Output}
    \label{fig:unicode_mode_comparison2}
  \end{subfigure}
  \caption{Examples of Image Mode Output}
\end{figure}

\subsection{Terminal Output using \texttt{ncurses}}
\label{sec:introduction:ncurses}

Therefore, the proposed render engine can be used in all terminals that support \texttt{ncurses} -- generally, any XTerm-like terminal will do.

\section{Related Work}
\label{sec:relatedwork}

% Summarize the previously published papers and books that are related to your
% proposed research. Whenever possible, you should compare and contrast your
% approach with the ones that have been discussed in the past. As you describe
% related papers, please make sure that you cite them
% properly~\cite{conrad-gecco-selection-study}.

To create an image, a ray-tracer first generates {\it eye-rays}, one for each pixel to render.
These rays have their origin at the camera, and a direction which causes the ray to pass through the pixel to render.
Each ray is then tested against all objects in the scene for intersection, and the intersection with the closest distance is chosen.
This was the only thing the original ray-traced shading algorithm \cite{appel1968some} did, after which the amount of illuminance incident on the point the ray hit, along with some information available from other algorithms (such as if the surface faced a light), dictated the level of darkness of that pixel.

% rewrite above (use stuff on doc) and continue thread three

\section{Method of Approach}
\label{sec:method}

% Use technical diagrams, equations, algorithms, and paragraphs of text to
% describe the research that you intend to complete. See the \LaTeX\ source file
% for the proposal to learn how Figure~~\ref{intro-fig1} and Table~~\ref{intro-tab1}
% were included. Be sure to number all figures and tables and to explicitly refer
% to them in your text.

Only recently has ray-tracing been able to achieve real-time levels of performance thanks to advances in GPU technology. Even more recently NVIDIA released its RTX series of GPUs that have hardware support for ray-tracing. However, although fascinating, this proposal will not focus on RTX hardware. Instead, research will be done on the OptiX API \cite{parker2010optix} for NVIDIA GPUs that enables GPU-accelerated ray-object intersection calculations. Although a CPU-only ray-tracer is completely possible, and likely the first step in embarking on the creation of \name, it is not likely to be performant enough for real-time graphics. Therefore leveraging either CUDA (a compute API for NVIDIA GPUs \cite{nvidia2011cuda}) directly, or utilizing OptiX will be required.

Here we cover the methematical basis for ray-tracing, along with technical details about the proposed implementation.
Much of the math is informed by Peter Shirley's excellect {\it Ray Tracing in One Weekend} \cite{shirley2016ray}, as well as the Morgan Kaufmann textbook {\it Physically Based Rendering: From Theory to Implementation} \cite{pharr2016physically}.


\subsection{Ray-Surface Intersection}

Scenes that can be ray-traced must be a collection of surfaces that are mathematically intersectable with a ray.
Any surface that can be defined by $f(\vec{p}) = 0$, that is, $f(\vec{p})$ is $0$ when $\vec{p}$ is on the surface, is intersectable with a ray.
The point of intersection can be found by solving equation ~\ref{equation:ray_surface_intersection} for $t$ and then using formula ~\ref{equation:point_on_ray} to calculate the coordinates of that point on the ray.

\begin{equation}
  \label{equation:ray_surface_intersection}
  f(\rayorg + t\raydir) = 0
\end{equation}

In \name, the only surfaces that will be supported are spheres, triangles, and infinite planes, since their surface definition functions are mathematically simple.
For spheres, the surface definition function is function ~\ref{equation:sphere_surface}, with $S$ representing the sphere.
The intersection point between a ray and a sphere is given by solving equation ~\ref{equation:ray_sphere_intersection} for $t$ and then using formula ~\ref{equation:point_on_ray}.
Notice that equation ~\ref{equation:ray_sphere_intersection} is quadratic, and the number (and values) of the roots give us the $t$ we want to use. The smallest root greater than zero corresponds to the point on the ray which first intersected the sphere. If there are no real roots, then the ray does not intersect the sphere.

\begin{equation}
  \label{equation:sphere_surface}
  f(\vec{p}) = (\vec{p} - \vec{S_{center}})^2 - {S_{radius}}^2
\end{equation}

\begin{equation}
  \label{equation:ray_sphere_intersection}
  (\raydir^2)t^2 + 2(\raydir \cdot (\rayorg - \vec{S_{center}}))t + (\rayorg - \vec{S_{center}})^2 - {S_{radius}}^2 = 0
\end{equation}

For planes, the surface definition function is function ~\ref{equation:plane_surface}, with $P$ representing the plane.
The plane's {\it offset} is a point on the plane, and the plane's {\it normal} is a vector perpendicular to the plane.
The intersection point between a ray and a plane is given by solving equation ~\ref{equation:ray_plane_intersection} for $t$ and then using formula ~\ref{equation:point_on_ray}.

\begin{equation}
  \label{equation:plane_surface}
  f(\vec{p}) = (\vec{p} - \vec{o}) \cdot \vec{n}
\end{equation}

\begin{equation}
  \label{equation:ray_plane_intersection}
  (\vec{P_{normal}} \cdot \raydir)t + \vec{P_{normal}} \cdot (\rayorg - \vec{P_{offset}}) = 0
\end{equation}

For triangles, the intersection is a bit more complicated. First, intersection is tested with the plane the polygon lies in -- that results in some intersection point $Q$. Then,

  % continue writing thread four

\subsection{Rendering Equation}
\label{sec:method:rendering_equation}
Equation \ref{equation:rendering} is a slightly simplified form of the rendering equation, removing properties dealing with the wavelength of light and time.

\begin{equation}
  \label{equation:rendering}
  L_{out}(\vec{x}, \vec{w}) = L_{emit}(\vec{x}, \vec{w}) + \int_{\Omega} f_r(\vec{x}, \vec{v},\vec{w})f_i(\vec{x}, \vec{v})(-\vec{v} \cdot n) dv
\end{equation}

\subsection{Ray-Character Translation Algorithm}
\label{sec:method:ray_character_algorithm}

To translate the color result of a ray-trace to an actual character pixel, a similarity test is used. This algorithm is loosely inspired by the pixel to character translation algorithm used in TerminalImageViewer \cite{tivGithub}; however, it has less input data -- instead of a 4 by 8 pixel field, only a few ray-traced color results are available.

\section{Evaluation Strategy}
\label{sec:evaluate}

% Explain what steps you will take to evaluate your proposed method. If you intend
% to conduct experiments, then you must clearly define your evaluation metrics.

\section{Research Schedule}
\label{sec:schedule}

% Identify the main phases and tasks of your research project and set deadlines
% for when you will be able to complete each of these items.

\section{Conclusion}
\label{sec:conclusion}

% Provide a summary of your proposed research and suggest the impact that it may
% have on the discipline of computer science. If possible, you may also suggest
% some areas for future research.

\bibliographystyle{plain}
\bibliography{senior_thesis_proposal}
\end{document}
